{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Bayesian Neural Network.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNpm6w5UhQenfA5pdQmt279",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guillermohenrion/AI/blob/master/Bayesian_Neural_Network.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baC8Y57rwgd5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load libriaries and functions.\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "tfk = tf.keras\n",
        "tf.keras.backend.set_floatx(\"float64\")\n",
        "import tensorflow_probability as tfp\n",
        "tfd = tfp.distributions\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import IsolationForest\n",
        "# Define helper functions.\n",
        "scaler = StandardScaler()\n",
        "detector = IsolationForest(n_estimators=1000, behaviour=\"deprecated\", contamination=\"auto\", random_state=0)\n",
        "neg_log_likelihood = lambda x, rv_x: -rv_x.log_prob(x)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE2kZ-x1Mq77",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load data and keep only first six months due to drift.\n",
        "data = pd.read_excel(\"AirQualityUCI.xlsx\")\n",
        "data = data[data[\"Date\"] <= \"2004-09-10\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5iJy-vmNSpf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Select columns and remove rows with missing values.\n",
        "columns = [\"PT08.S1(CO)\", \"PT08.S3(NOx)\", \"PT08.S4(NO2)\", \"PT08.S5(O3)\", \"T\", \"AH\", \"CO(GT)\", \"C6H6(GT)\", \"NOx(GT)\", \"NO2(GT)\"]\n",
        "data = data[columns].dropna(axis=0)\n",
        "# Scale data to zero mean and unit variance.\n",
        "X_t = scaler.fit_transform(data)\n",
        "# Remove outliers.\n",
        "is_inlier = detector.fit_predict(X_t)\n",
        "X_t = X_t[(is_inlier > 0),:]\n",
        "# Restore frame.\n",
        "dataset = pd.DataFrame(X_t, columns=columns)\n",
        "# Select labels for inputs and outputs.\n",
        "inputs = [\"PT08.S1(CO)\", \"PT08.S3(NOx)\", \"PT08.S4(NO2)\", \"PT08.S5(O3)\", \"T\", \"AH\"]\n",
        "outputs = [\"CO(GT)\", \"C6H6(GT)\", \"NOx(GT)\", \"NO2(GT)\"]"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a4llP5SINU5O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define some hyperparameters.\n",
        "n_epochs = 50\n",
        "n_samples = dataset.shape[0]\n",
        "n_batches = 10\n",
        "batch_size = np.floor(n_samples/n_batches)\n",
        "buffer_size = n_samples\n",
        "# Define training and test data sizes.\n",
        "n_train = int(0.7*dataset.shape[0])\n",
        "# Define dataset instance.\n",
        "data = tf.data.Dataset.from_tensor_slices((dataset[inputs].values, dataset[outputs].values))\n",
        "data = data.shuffle(n_samples, reshuffle_each_iteration=True)\n",
        "# Define train and test data instances.\n",
        "data_train = data.take(n_train).batch(batch_size).repeat(n_epochs)\n",
        "data_test = data.skip(n_train).batch(1).repeat(n_epochs)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nd8FQ1ltNXAu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "outputId": "d7414e27-5adc-4736-88a6-2dde7a6ab586"
      },
      "source": [
        "# Define prior for regularization.\n",
        "prior = tfd.Independent(tfd.Normal(loc=tf.zeros(len(outputs), dtype=tf.float64), scale=1.0), reinterpreted_batch_ndims=1)\n",
        "# Define model instance.\n",
        "model = tfk.Sequential([\n",
        "tfk.layers.InputLayer(input_shape=(len(inputs),), name=\"input\"),\n",
        "tfk.layers.Dense(10, activation=\"relu\", name=\"dense_1\"),\n",
        "tfk.layers.Dense(tfp.layers.MultivariateNormalTriL.params_size(\n",
        "len(outputs)), activation=None, name=\"distribution_weights\"),\n",
        "tfp.layers.MultivariateNormalTriL(len(outputs), activity_regularizer=tfp.layers.KLDivergenceRegularizer(prior, weight=1/n_batches), name=\"output\")\n",
        "], name=\"model\")\n",
        "# Compile model.\n",
        "model.compile(optimizer=\"adam\", loss=neg_log_likelihood)\n",
        "# Run training session.\n",
        "model.fit(data_train, epochs=n_epochs, validation_data=data_test, verbose=False)\n",
        "# Describe model.\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/linalg/linear_operator_lower_triangular.py:158: calling LinearOperator.__init__ (from tensorflow.python.ops.linalg.linear_operator) with graph_parents is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Do not pass `graph_parents`.  They will  no longer be used.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uCTUWp4_NZuV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tfp.layers.DenseFlipout(10, activation=\"relu\", name=\"dense_1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Bj_M7IRNcYe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict.\n",
        "samples = 500\n",
        "iterations = 10\n",
        "test_iterator = tf.compat.v1.data.make_one_shot_iterator(data_test)\n",
        "X_true, Y_true, Y_pred = np.empty(shape=(samples, len(inputs))), np.empty(shape=(samples, len(outputs))), np.empty(shape=(samples, len(outputs), iterations))\n",
        "for i in range(samples):\n",
        "    features, labels = test_iterator.get_next()\n",
        "    X_true[i,:] = features\n",
        "    Y_true[i,:] = labels.numpy()\n",
        "    for k in range(iterations):\n",
        "        Y_pred[i,:,k] = model.predict(features)\n",
        "        \n",
        "# Calculate mean and standard deviation.\n",
        "Y_pred_m = np.mean(Y_pred, axis=-1)\n",
        "Y_pred_s = np.std(Y_pred, axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}